{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Mental Health Dataset.csv')\n",
    "\n",
    "# https://www.kaggle.com/datasets/bhavikjikadara/mental-health-dataset\n",
    "\n",
    "# Alle Spalten anzeigen\n",
    "pd.set_option('display.max_columns', len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Country</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>self_employed</th>\n",
       "      <th>family_history</th>\n",
       "      <th>treatment</th>\n",
       "      <th>Days_Indoors</th>\n",
       "      <th>Growing_Stress</th>\n",
       "      <th>Changes_Habits</th>\n",
       "      <th>Mental_Health_History</th>\n",
       "      <th>Mood_Swings</th>\n",
       "      <th>Coping_Struggles</th>\n",
       "      <th>Work_Interest</th>\n",
       "      <th>Social_Weakness</th>\n",
       "      <th>mental_health_interview</th>\n",
       "      <th>care_options</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-08-27 11:29:31</td>\n",
       "      <td>Female</td>\n",
       "      <td>United States</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1-14 days</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medium</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Not sure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-08-27 11:31:50</td>\n",
       "      <td>Female</td>\n",
       "      <td>United States</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1-14 days</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medium</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-08-27 11:32:39</td>\n",
       "      <td>Female</td>\n",
       "      <td>United States</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1-14 days</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medium</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-08-27 11:37:59</td>\n",
       "      <td>Female</td>\n",
       "      <td>United States</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1-14 days</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medium</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Maybe</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-27 11:43:36</td>\n",
       "      <td>Female</td>\n",
       "      <td>United States</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1-14 days</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medium</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Timestamp  Gender        Country Occupation self_employed  \\\n",
       "0  2014-08-27 11:29:31  Female  United States  Corporate           NaN   \n",
       "1  2014-08-27 11:31:50  Female  United States  Corporate           NaN   \n",
       "2  2014-08-27 11:32:39  Female  United States  Corporate           NaN   \n",
       "3  2014-08-27 11:37:59  Female  United States  Corporate            No   \n",
       "4  2014-08-27 11:43:36  Female  United States  Corporate            No   \n",
       "\n",
       "  family_history treatment Days_Indoors Growing_Stress Changes_Habits  \\\n",
       "0             No       Yes    1-14 days            Yes             No   \n",
       "1            Yes       Yes    1-14 days            Yes             No   \n",
       "2            Yes       Yes    1-14 days            Yes             No   \n",
       "3            Yes       Yes    1-14 days            Yes             No   \n",
       "4            Yes       Yes    1-14 days            Yes             No   \n",
       "\n",
       "  Mental_Health_History Mood_Swings Coping_Struggles Work_Interest  \\\n",
       "0                   Yes      Medium               No            No   \n",
       "1                   Yes      Medium               No            No   \n",
       "2                   Yes      Medium               No            No   \n",
       "3                   Yes      Medium               No            No   \n",
       "4                   Yes      Medium               No            No   \n",
       "\n",
       "  Social_Weakness mental_health_interview care_options  \n",
       "0             Yes                      No     Not sure  \n",
       "1             Yes                      No           No  \n",
       "2             Yes                      No          Yes  \n",
       "3             Yes                   Maybe          Yes  \n",
       "4             Yes                      No          Yes  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 292364 entries, 0 to 292363\n",
      "Data columns (total 17 columns):\n",
      " #   Column                   Non-Null Count   Dtype \n",
      "---  ------                   --------------   ----- \n",
      " 0   Timestamp                292364 non-null  object\n",
      " 1   Gender                   292364 non-null  object\n",
      " 2   Country                  292364 non-null  object\n",
      " 3   Occupation               292364 non-null  object\n",
      " 4   self_employed            287162 non-null  object\n",
      " 5   family_history           292364 non-null  object\n",
      " 6   treatment                292364 non-null  object\n",
      " 7   Days_Indoors             292364 non-null  object\n",
      " 8   Growing_Stress           292364 non-null  object\n",
      " 9   Changes_Habits           292364 non-null  object\n",
      " 10  Mental_Health_History    292364 non-null  object\n",
      " 11  Mood_Swings              292364 non-null  object\n",
      " 12  Coping_Struggles         292364 non-null  object\n",
      " 13  Work_Interest            292364 non-null  object\n",
      " 14  Social_Weakness          292364 non-null  object\n",
      " 15  mental_health_interview  292364 non-null  object\n",
      " 16  care_options             292364 non-null  object\n",
      "dtypes: object(17)\n",
      "memory usage: 37.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292364, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dieser Datensatz besitz 363 Duplikate.\n"
     ]
    }
   ],
   "source": [
    "print('Dieser Datensatz besitz ' + str(df.duplicated().sum()) + ' Duplikate.')\n",
    "#duplicates = df[df.duplicated(keep=False)].sort_values(by=list(df.columns))\n",
    "#duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kategorische Variablen: ['Timestamp', 'Gender', 'Country', 'Occupation', 'self_employed', 'family_history', 'treatment', 'Days_Indoors', 'Growing_Stress', 'Changes_Habits', 'Mental_Health_History', 'Mood_Swings', 'Coping_Struggles', 'Work_Interest', 'Social_Weakness', 'mental_health_interview', 'care_options']\n",
      "Numerische Variablen: []\n"
     ]
    }
   ],
   "source": [
    "categoricalVar = [col for col in df if df[col].dtype == 'object']\n",
    "print('Kategorische Variablen: ' + str(categoricalVar))\n",
    "\n",
    "numericalVar = [col for col in df if df[col].dtype != 'object']\n",
    "print('Numerische Variablen: '+ str(numericalVar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "self_employed    5202\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()[df.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jf/k1y_jzxs5177jm_fgv__dnww0000gn/T/ipykernel_16284/341960323.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_prep['self_employed'].fillna('unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_prep['self_employed'].fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unwichtige Spalten löschen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "notRelevantVar =['Timestamp', 'mental_health_interview']\n",
    "\n",
    "df_prep.drop(notRelevantVar, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Werte ändern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                    2\n",
       "Country                  35\n",
       "Occupation                5\n",
       "self_employed             3\n",
       "family_history            2\n",
       "treatment                 2\n",
       "Days_Indoors              5\n",
       "Growing_Stress            3\n",
       "Changes_Habits            3\n",
       "Mental_Health_History     3\n",
       "Mood_Swings               3\n",
       "Coping_Struggles          2\n",
       "Work_Interest             3\n",
       "Social_Weakness           3\n",
       "care_options              3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Anzahl der Uniquen Werte ausgeben lassen\n",
    "df_prep.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Gender': {'Female': 0, 'Male': 1}, 'family_history': {'No': 0, 'Yes': 1}, 'treatment': {'Yes': 0, 'No': 1}, 'Coping_Struggles': {'No': 0, 'Yes': 1}}\n"
     ]
    }
   ],
   "source": [
    "# Funktion: Binäre Werte in 0/1 ändern\n",
    "# Input: Datensatz\n",
    "# Output: Datensatz mit den neuen Werte, Mapping Dictionary \n",
    "# Funktionsweise: \n",
    "    # 1. Erstellung eines Mapping Dictionarys, \n",
    "    # 2. Die einzelnen Spalten werden durchgegangen und bei jenen wo die anzahl der einzigartigen Werte gleich zwei ist, wird der erste Werte gleich 0 gesetzt und der zweite auf 1\n",
    "    # 3. Die Zuordnung der Werte wird in dem Mapping Dictionary festgehalten\n",
    "def binaer_mapping_function(df):\n",
    "    mapping_dict = {}\n",
    "    for col in df.columns:\n",
    "        if len(df[col].unique()) == 2:\n",
    "            mapping_dict[col] = {df[col].unique()[0]: 0, df[col].unique()[1]: 1}\n",
    "            df[col] = df[col].map(mapping_dict[col])\n",
    "    return df, mapping_dict\n",
    "\n",
    "\n",
    "df_prep, mapping_dict = binaer_mapping_function(df_prep)\n",
    "print(mapping_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Country',\n",
       " 'Occupation',\n",
       " 'self_employed',\n",
       " 'Days_Indoors',\n",
       " 'Growing_Stress',\n",
       " 'Changes_Habits',\n",
       " 'Mental_Health_History',\n",
       " 'Mood_Swings',\n",
       " 'Work_Interest',\n",
       " 'Social_Weakness',\n",
       " 'care_options']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_columns_moreThanTwoUniqueValues = df.columns[df.nunique() > 2].to_list()\n",
    "list_columns_moreThanTwoUniqueValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for categorical variables\n",
    "for var in list_columns_moreThanTwoUniqueValues:\n",
    "    dummies = pd.get_dummies(df_prep[var], prefix=var, dtype=int)\n",
    "    df_prep = pd.concat([df_prep, dummies], axis=1)\n",
    "    df_prep.drop(var, axis=1, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 292364 entries, 0 to 292363\n",
      "Data columns (total 73 columns):\n",
      " #   Column                           Non-Null Count   Dtype\n",
      "---  ------                           --------------   -----\n",
      " 0   Gender                           292364 non-null  int64\n",
      " 1   family_history                   292364 non-null  int64\n",
      " 2   treatment                        292364 non-null  int64\n",
      " 3   Coping_Struggles                 292364 non-null  int64\n",
      " 4   Country_Australia                292364 non-null  int64\n",
      " 5   Country_Belgium                  292364 non-null  int64\n",
      " 6   Country_Bosnia and Herzegovina   292364 non-null  int64\n",
      " 7   Country_Brazil                   292364 non-null  int64\n",
      " 8   Country_Canada                   292364 non-null  int64\n",
      " 9   Country_Colombia                 292364 non-null  int64\n",
      " 10  Country_Costa Rica               292364 non-null  int64\n",
      " 11  Country_Croatia                  292364 non-null  int64\n",
      " 12  Country_Czech Republic           292364 non-null  int64\n",
      " 13  Country_Denmark                  292364 non-null  int64\n",
      " 14  Country_Finland                  292364 non-null  int64\n",
      " 15  Country_France                   292364 non-null  int64\n",
      " 16  Country_Georgia                  292364 non-null  int64\n",
      " 17  Country_Germany                  292364 non-null  int64\n",
      " 18  Country_Greece                   292364 non-null  int64\n",
      " 19  Country_India                    292364 non-null  int64\n",
      " 20  Country_Ireland                  292364 non-null  int64\n",
      " 21  Country_Israel                   292364 non-null  int64\n",
      " 22  Country_Italy                    292364 non-null  int64\n",
      " 23  Country_Mexico                   292364 non-null  int64\n",
      " 24  Country_Moldova                  292364 non-null  int64\n",
      " 25  Country_Netherlands              292364 non-null  int64\n",
      " 26  Country_New Zealand              292364 non-null  int64\n",
      " 27  Country_Nigeria                  292364 non-null  int64\n",
      " 28  Country_Philippines              292364 non-null  int64\n",
      " 29  Country_Poland                   292364 non-null  int64\n",
      " 30  Country_Portugal                 292364 non-null  int64\n",
      " 31  Country_Russia                   292364 non-null  int64\n",
      " 32  Country_Singapore                292364 non-null  int64\n",
      " 33  Country_South Africa             292364 non-null  int64\n",
      " 34  Country_Sweden                   292364 non-null  int64\n",
      " 35  Country_Switzerland              292364 non-null  int64\n",
      " 36  Country_Thailand                 292364 non-null  int64\n",
      " 37  Country_United Kingdom           292364 non-null  int64\n",
      " 38  Country_United States            292364 non-null  int64\n",
      " 39  Occupation_Business              292364 non-null  int64\n",
      " 40  Occupation_Corporate             292364 non-null  int64\n",
      " 41  Occupation_Housewife             292364 non-null  int64\n",
      " 42  Occupation_Others                292364 non-null  int64\n",
      " 43  Occupation_Student               292364 non-null  int64\n",
      " 44  self_employed_No                 292364 non-null  int64\n",
      " 45  self_employed_Yes                292364 non-null  int64\n",
      " 46  self_employed_unknown            292364 non-null  int64\n",
      " 47  Days_Indoors_1-14 days           292364 non-null  int64\n",
      " 48  Days_Indoors_15-30 days          292364 non-null  int64\n",
      " 49  Days_Indoors_31-60 days          292364 non-null  int64\n",
      " 50  Days_Indoors_Go out Every day    292364 non-null  int64\n",
      " 51  Days_Indoors_More than 2 months  292364 non-null  int64\n",
      " 52  Growing_Stress_Maybe             292364 non-null  int64\n",
      " 53  Growing_Stress_No                292364 non-null  int64\n",
      " 54  Growing_Stress_Yes               292364 non-null  int64\n",
      " 55  Changes_Habits_Maybe             292364 non-null  int64\n",
      " 56  Changes_Habits_No                292364 non-null  int64\n",
      " 57  Changes_Habits_Yes               292364 non-null  int64\n",
      " 58  Mental_Health_History_Maybe      292364 non-null  int64\n",
      " 59  Mental_Health_History_No         292364 non-null  int64\n",
      " 60  Mental_Health_History_Yes        292364 non-null  int64\n",
      " 61  Mood_Swings_High                 292364 non-null  int64\n",
      " 62  Mood_Swings_Low                  292364 non-null  int64\n",
      " 63  Mood_Swings_Medium               292364 non-null  int64\n",
      " 64  Work_Interest_Maybe              292364 non-null  int64\n",
      " 65  Work_Interest_No                 292364 non-null  int64\n",
      " 66  Work_Interest_Yes                292364 non-null  int64\n",
      " 67  Social_Weakness_Maybe            292364 non-null  int64\n",
      " 68  Social_Weakness_No               292364 non-null  int64\n",
      " 69  Social_Weakness_Yes              292364 non-null  int64\n",
      " 70  care_options_No                  292364 non-null  int64\n",
      " 71  care_options_Not sure            292364 non-null  int64\n",
      " 72  care_options_Yes                 292364 non-null  int64\n",
      "dtypes: int64(73)\n",
      "memory usage: 162.8 MB\n"
     ]
    }
   ],
   "source": [
    "df_ml = df_prep\n",
    "df_ml.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten in Traings und Testdaten teilen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "treatment\n",
       "0    147606\n",
       "1    144758\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml['treatment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_ml['treatment']\n",
    "X = df_ml.loc[:,df_ml.columns != 'treatment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7399483522309442\n",
      "Precision: 0.75964414158622\n",
      "Recall: 0.6937731217370259\n",
      "F1 Score: 0.7252159456431385\n",
      "ROC AUC: 0.7394584728820492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "\n",
    "rf = RandomForestClassifier(criterion='entropy', n_estimators=500, random_state=33)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "precision = precision_score(y_test, y_pred_rf)\n",
    "recall = recall_score(y_test, y_pred_rf)\n",
    "f1 = f1_score(y_test, y_pred_rf)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_rf)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7586920459015272\n",
      "Precision: 0.784942099796099\n",
      "Recall: 0.7054247484700757\n",
      "F1 Score: 0.7430621312550076\n",
      "ROC AUC: 0.7581269258424829\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", eval_metric = 'auc', \n",
    "random_state=33, n_estimators=500, learning_rate=0.2)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "precision = precision_score(y_test, y_pred_xgb)\n",
    "recall = recall_score(y_test, y_pred_xgb)\n",
    "f1 = f1_score(y_test, y_pred_xgb)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_xgb)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7169804867203666\n",
      "Precision: 0.7322098783966371\n",
      "Recall: 0.6745150917954569\n",
      "F1 Score: 0.7021793510536829\n",
      "ROC AUC: 0.7165299655254781\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred_continuous = regressor.predict(X_test)\n",
    "\n",
    "\n",
    "# Umwandlung in Binäre Klassifikation (>= 0 -> 1, <0 -> 0) ?????????????????\n",
    "temp = 0.5\n",
    "y_pred_linRegression_binary = (y_pred_continuous >= temp).astype(int)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_linRegression_binary)\n",
    "precision = precision_score(y_test, y_pred_linRegression_binary)\n",
    "recall = recall_score(y_test, y_pred_linRegression_binary)\n",
    "f1 = f1_score(y_test, y_pred_linRegression_binary)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_linRegression_binary) # !!!!!!\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='poly', probability=True)  \n",
    "svc.fit(X_train, y_train)\n",
    "# y_pred_svm = svc.predict(X_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "# precision = precision_score(y_test, y_pred_svm)\n",
    "# recall = recall_score(y_test, y_pred_svm)\n",
    "# f1 = f1_score(y_test, y_pred_svm)\n",
    "# roc_auc = roc_auc_score(y_test, y_pred_svm) # !!!!!!\n",
    "\n",
    "# # Ergebnisse ausgeben\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "# print(\"Precision:\", precision)\n",
    "# print(\"Recall:\", recall)\n",
    "# print(\"F1 Score:\", f1)\n",
    "# print(\"ROC AUC:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "\n",
    "# svc = SVC(kernel='poly')  # Du kannst den Kernel auch ändern, z.B. 'rbf', 'poly', etc.\n",
    "# svc.fit(X_train, y_train)\n",
    "# y_pred = svc.predict(X_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f'Genauigkeit: {accuracy * 100:.2f}%')\n",
    "\n",
    "# # plot_confusion_matrix_model(y_pred)\n",
    "# # results(svc, 'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def results(model, modelname):\n",
    "#     # Predicting the test set results\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for ROC curve\n",
    "\n",
    "#     # Evaluating the model\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     precision = precision_score(y_test, y_pred)\n",
    "#     recall = recall_score(y_test, y_pred)\n",
    "#     f1 = f1_score(y_test, y_pred)\n",
    "#     roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "#     labelname= modelname + ' (area = %0.2f)' % roc_auc\n",
    "\n",
    "\n",
    "#     # Plotting ROC curve\n",
    "#     fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "#     plt.figure()\n",
    "#     plt.plot(fpr, tpr, label=labelname)\n",
    "#     plt.plot([0, 1], [0, 1], 'k--')\n",
    "#     plt.xlim([0.0, 1.0])\n",
    "#     plt.ylim([0.0, 1.05])\n",
    "#     plt.xlabel('False Positive Rate')\n",
    "#     plt.ylabel('True Positive Rate')\n",
    "#     plt.title('Receiver Operating Characteristic')\n",
    "#     plt.legend(loc=\"lower right\")\n",
    "#     plt.show()\n",
    "\n",
    "#     # Print the scores\n",
    "#     print(f'Accuracy: {accuracy}')\n",
    "#     print(f'Precision: {precision}')\n",
    "#     print(f'Recall: {recall}')\n",
    "#     print(f'F1 Score: {f1}')\n",
    "#     print(f'ROC AUC: {roc_auc}')\n",
    "\n",
    "\n",
    "# def plot_confusion_matrix(cm, classes,\n",
    "#                           normalize=False,\n",
    "#                           title='Confusion matrix',\n",
    "#                           cmap=plt.cm.Blues):\n",
    "#     \"\"\"\n",
    "#     This function prints and plots the confusion matrix.\n",
    "#     Normalization can be applied by setting `normalize=True`.\n",
    "#     \"\"\"\n",
    "#     if normalize:\n",
    "#         cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "#     else:\n",
    "#         print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "#     plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar()\n",
    "#     tick_marks = np.arange(len(classes))\n",
    "#     plt.xticks(tick_marks, classes, rotation=45)\n",
    "#     plt.yticks(tick_marks, classes)\n",
    "\n",
    "#     fmt = '.2f' if normalize else 'd'\n",
    "#     thresh = cm.max() / 2.\n",
    "#     for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "#         plt.text(j, i, format(cm[i, j], fmt),\n",
    "#                  horizontalalignment=\"center\",\n",
    "#                  color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "#     plt.ylabel('True label')\n",
    "#     plt.xlabel('Predicted label')\n",
    "#     plt.tight_layout()\n",
    "\n",
    "\n",
    "# def plot_confusion_matrix_model(y_predicted_labels):\n",
    "#     cnf_matrix = confusion_matrix(y_test, y_predicted_labels)\n",
    "#     np.set_printoptions(precision=2)\n",
    "#     cnf_matrix\n",
    "\n",
    "#     fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "#     #Without Normalization\n",
    "#     plt.sca(axes[0])  \n",
    "#     plot_confusion_matrix(cnf_matrix, classes=[0, 1], title='Confusion matrix, without normalization')\n",
    "\n",
    "#     # Mit Normalisierung\n",
    "#     plt.sca(axes[1]) \n",
    "#     plot_confusion_matrix(cnf_matrix, classes=[0, 1], normalize=True, title='Normalized confusion matrix')\n",
    "\n",
    "#     # Zeige die Figur\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# forest = RandomForestClassifier(criterion='entropy', n_estimators=500, random_state=33)\n",
    "# forest.fit(X_train, y_train)\n",
    "# y_predicted_labels = forest.predict(X_test)\n",
    "\n",
    "# plot_confusion_matrix_model(y_predicted_labels)\n",
    "# results(forest, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# n_estimators = [100, 500, 1000]\n",
    "# max_features = ['auto', 'sqrt']\n",
    "# max_depth = [20, 50, 100]\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# min_samples_leaf = [1, 3, 5]\n",
    "# bootstrap = [True, False]\n",
    "\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "# print(random_grid)\n",
    "\n",
    "# rf = RandomForestClassifier()\n",
    "# rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 2, verbose=2, random_state=33, n_jobs = -1)\n",
    "# rf_random.fit(X_train, y_train)\n",
    "\n",
    "# rf_random.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# forest = RandomForestClassifier(\n",
    "#     criterion='entropy', n_estimators=100, random_state=123, min_samples_split = 10, min_samples_leaf = 3, max_features = 'sqrt', max_depth = 20, bootstrap = True)\n",
    "# forest.fit(X_train, y_train)\n",
    "# y_predicted_labels = forest.predict(X_test)\n",
    "\n",
    "\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Predicting the test set results\n",
    "# y_pred = forest.predict(X_test)\n",
    "# y_proba = forest.predict_proba(X_test)[:, 1]  # Probabilities for ROC curve\n",
    "\n",
    "# # Evaluating the model\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# precision = precision_score(y_test, y_pred)\n",
    "# recall = recall_score(y_test, y_pred)\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "# roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# # Plotting ROC curve\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "# plt.figure()\n",
    "# plt.plot(fpr, tpr, label='Random Forest (area = %0.2f)' % roc_auc)\n",
    "# plt.plot([0, 1], [0, 1], 'k--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver Operating Characteristic')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()\n",
    "\n",
    "# # Print the scores\n",
    "# print(f'Accuracy: {accuracy}')\n",
    "# print(f'Precision: {precision}')\n",
    "# print(f'Recall: {recall}')\n",
    "# print(f'F1 Score: {f1}')\n",
    "# print(f'ROC AUC: {roc_auc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "\n",
    "# xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", eval_metric = 'auc', \n",
    "# random_state=33, n_estimators=500, learning_rate=0.2)\n",
    "# xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# y_pred_xgb = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Confusion Matrix\n",
    "# # Compute confusion matrix\n",
    "# cnf_matrix_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
    "# np.set_printoptions(precision=2)\n",
    "\n",
    "# #With Normalization\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix_xgb, classes= [0,1],\n",
    "#                       title='Confusion matrix, without normalization')\n",
    "# # With normalization\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix_xgb, classes= [0,1], normalize=True,\n",
    "#                       title='Normalized confusion matrix')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predicting the test set results\n",
    "\n",
    "# y_proba_xgb = forest.predict_proba(X_test)[:, 1]  # Probabilities for ROC curve\n",
    "\n",
    "# # Evaluating the model\n",
    "# accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "# precision = precision_score(y_test, y_pred_xgb)\n",
    "# recall = recall_score(y_test, y_pred_xgb)\n",
    "# f1 = f1_score(y_test, y_pred_xgb)\n",
    "# roc_auc = roc_auc_score(y_test, y_proba_xgb)\n",
    "\n",
    "# # Plotting ROC curve\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_proba_xgb)\n",
    "# plt.figure()\n",
    "# plt.plot(fpr, tpr, label='Random Forest (area = %0.2f)' % roc_auc)\n",
    "# plt.plot([0, 1], [0, 1], 'k--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver Operating Characteristic')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()\n",
    "\n",
    "# # Print the scores\n",
    "# print(f'Accuracy: {accuracy}')\n",
    "# print(f'Precision: {precision}')\n",
    "# print(f'Recall: {recall}')\n",
    "# print(f'F1 Score: {f1}')\n",
    "# print(f'ROC AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# regressor = LinearRegression()\n",
    "# regressor.fit(X_train, y_train)\n",
    "# y_pred_continuous = regressor.predict(X_test)\n",
    "\n",
    "\n",
    "# # Umwandlung in Binäre Klassifikation (>= 0 -> 1, <0 -> 0) ?????????????????\n",
    "# temp = 0.5\n",
    "# y_pred_binary = (y_pred_continuous >= temp).astype(int)\n",
    "\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "# precision = precision_score(y_test, y_pred_binary)\n",
    "# recall = recall_score(y_test, y_pred_binary)\n",
    "# f1 = f1_score(y_test, y_pred_binary)\n",
    "# roc_auc = roc_auc_score(y_test, y_pred_binary) # !!!!!!\n",
    "\n",
    "# # Ergebnisse ausgeben\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "# print(\"Precision:\", precision)\n",
    "# print(\"Recall:\", recall)\n",
    "# print(\"F1 Score:\", f1)\n",
    "# print(\"ROC AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "\n",
    "# svc = SVC(kernel='poly')  # Du kannst den Kernel auch ändern, z.B. 'rbf', 'poly', etc.\n",
    "# svc.fit(X_train, y_train)\n",
    "# y_pred = svc.predict(X_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f'Genauigkeit: {accuracy * 100:.2f}%')\n",
    "\n",
    "# # plot_confusion_matrix_model(y_pred)\n",
    "# # results(svc, 'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Datensatz erstellen\n",
    "# data = {\n",
    "#     'Alter': [25, 45, 35, 50, 23, 39, 28, 41, 30, 52, 27, 33],\n",
    "#     'Einkommen': [30, 50, 60, 40, 25, 55, 45, 35, 50, 65, 40, 55],\n",
    "#     'Anzahl_Besuche': [5, 2, 3, 4, 6, 1, 3, 2, 4, 5, 1, 3],\n",
    "#     'Ausgaben': [500, 200, 300, 400, 600, 100, 250, 150, 350, 450, 80, 300],\n",
    "#     'Zufriedenheit': [4, 3, 5, 2, 5, 3, 4, 2, 4, 3, 1, 5],\n",
    "#     'Kaufentscheidung': [1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1]\n",
    "# }\n",
    "\n",
    "# # In DataFrame umwandeln\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # Merkmale und Zielvariable definieren\n",
    "# X = df[['Alter', 'Einkommen', 'Anzahl_Besuche', 'Ausgaben', 'Zufriedenheit']]\n",
    "# y = df['Kaufentscheidung']\n",
    "\n",
    "# # Datensatz in Trainings- und Testdaten aufteilen\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# # SVM Modell erstellen und trainieren\n",
    "# svm_model = SVC(kernel='linear')\n",
    "# svm_model.fit(X_train, y_train)\n",
    "\n",
    "# # Vorhersagen auf den Testdaten\n",
    "# y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# # Genauigkeit berechnen\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f'Genauigkeit: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble Methode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# # Annahme: Sie haben bereits trainierte Modelle rf und xgb\n",
    "\n",
    "# # Erstellen des Ensembles\n",
    "# ensemble = VotingClassifier(estimators=[\n",
    "#     ('random_forest', forest),\n",
    "#     ('xgboost', xgb_model)\n",
    "# ], voting='soft')  # 'soft' Voting für Wahrscheinlichkeiten\n",
    "\n",
    "# # Ensemble trainieren\n",
    "# ensemble.fit(X_train, y_train)\n",
    "\n",
    "# # Vorhersagen machen\n",
    "# predictions = ensemble.predict(X_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, predictions)\n",
    "# precision = precision_score(y_test, predictions)\n",
    "# recall = recall_score(y_test, predictions)\n",
    "# f1 = f1_score(y_test, predictions)\n",
    "# roc_auc = roc_auc_score(y_test, predictions)\n",
    "\n",
    "# # Ergebnisse ausgeben\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "# print(\"Precision:\", precision)\n",
    "# print(\"Recall:\", recall)\n",
    "# print(\"F1 Score:\", f1)\n",
    "# print(\"ROC AUC:\", roc_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
