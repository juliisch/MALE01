{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digital Business University of Applied Sciences\n",
    "\n",
    "Data Science und Management (M. Sc.)\n",
    "\n",
    "MALE01 Machine Learning\n",
    "\n",
    "Prof. Dr. Daniel Ambach\n",
    "\n",
    "Julia Schmid (200022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Vergleich datenbasierter und modellbasierte Methoden zur Behebung unausgeglichener Datensätze hinsichtlich der Vorhersageleistung und Fairness in Klassifikationsmodellen des maschinellen Lernens\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problemstellung**\n",
    "\n",
    "In Datensätzen tritt häufig das Problem einer starken Ungleichverteilung der Zielvariablen auf. Dies kann unterschiedliche Ursachen haben, wie etwa natürliche Häufigkeiten oder fehlerhafte Datenerhebung. Es kann vorkommen, dass in der Minderheitsklasse wichtige Informationen, wie beispielsweise seltene medizinische Diagnosen, enthalten. Die Folgen einer ungleichmäßigen Klassenverteilung sind verzerrte Ergebnisse, wodurch bestimmte Gruppen systematisch benachteiligt werden und somit die Fairness des Modells beeinträchtigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importe\n",
    "# Standardbibliotheken\n",
    "import os\n",
    "import pandas as pd \n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# Visualisierung\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Profilingreport\n",
    "from ydata_profiling import ProfileReport\n",
    "import webbrowser\n",
    "\n",
    "# Modelle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Metriken\n",
    "from sklearn.metrics import (f1_score, roc_auc_score,roc_curve, auc, balanced_accuracy_score)\n",
    "from fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n",
    "\n",
    "# Sampling Methoden\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datenauswahl**\n",
    "\n",
    "Für den Vergleich der datenbasierten und algorithmusbasierten Methoden wurde der Datensatz Give Me Some Credit (Fusion & Cukierski, 2011) von Kaggle verwendet. Dieser Datensatz umfasst zwölf Variablen mit verschiedenen Kreditinformationen von 150.000 Bankkunden. Die Zielvariable SeriousDlqin2yrs gibt an, ob innerhalb von zwei Jahren ein Zahlungsverzug von mindestens 90 Tagen eingetreten ist. Dabei ist die Klasse \"kein Zahlungsausfall\" deutlich überrepräsentiert im Vergleich zur Klasse \"Zahlungsausfall\". Aufgrund dieser Ungleichverteilung eignet sich der Datensatz besonders gut, um datenbasierte und modellbasierte Methoden anzuwenden, zu evaluieren und miteinander zu vergleichen.\n",
    "\n",
    "| **Variablenname**                         | **Erklärung Variable**                                                                                   |\n",
    "|--------------------------------------------|----------------------------------------------------------------------------------------------------------|\n",
    "| SeriousDlqin2yrs                           | Zielvariable: Zahlungsverzug von 90 Tage oder länger                                                     |\n",
    "| RevolvingUtilizationOfUnsecuredLines       | Gesamter ausstehender Betrag auf Kreditkarten und persönlichen Krediten (ohne Immobilien- und Ratenkredite) |\n",
    "| age                                        | Alter                                                                                                    |\n",
    "| NumberOfTime30 59DaysPastDueNotWorse        | Anzahl der 30 bis 59 Tage überfälligen Zahlungen in den letzten zwei Jahren                              |\n",
    "| DebtRatio                                  | Verhältnis von monatlichen Schuldenzahlungen zum Bruttoeinkommen                                         |\n",
    "| MonthlyIncome                              | Monatliches Einkommen                                                                                   |\n",
    "| NumberOfOpenCreditLinesAndLoans            | Anzahl der offenen Kredite und Kreditlinien                                                              |\n",
    "| NumberOfTimes90DaysLate                    | Anzahl der Fälle, in denen 90 Tage oder länger ein Verzug vorliegt                                        |\n",
    "| NumberRealEstateLoansOrLines               | Anzahl der Immobilienkredite                                                                             |\n",
    "| NumberOfTime60 89DaysPastDueNotWorse        | Anzahl der 60 bis 89 Tage überfälligen Zahlungen in den letzten zwei Jahren                              |\n",
    "| NumberOfDependents                         | Anzahl der unterhaltsberechtigten Personen in der Familie                                                |\n",
    "\n",
    "(Fusion & Cukierski, 2011)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Daten verstehen** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_name = \"input/cs-training.csv\"\n",
    "df = pd.read_csv(input_file_name, encoding='latin1', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten beschreiben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der ersten 5 Zeilen\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der Anzahl der Zeilen und Spalten\n",
    "print(f'Anzahl Zeilen: {df.shape[0]}')\n",
    "print(f'Anzahl Spalten: {df.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der Datensatz-Info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der numerischen und kategorischen Variablen \n",
    "numericalVar = [col for col in df if df[col].dtype != 'object']\n",
    "print(numericalVar)\n",
    "\n",
    "categoricalVar = [col for col in df if df[col].dtype == 'object']\n",
    "print(categoricalVar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der statistischen Kennzahlen der numerischen Variablen\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten visualisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellung eines Profilingreports\n",
    "pr = ProfileReport(df, title = 'Credit Data') \n",
    "filename_pr = \"output/credit_data_pr.html\" \n",
    "path_pr = os.path.abspath(filename_pr) \n",
    "\n",
    "pr.to_file(path_pr)  # ProfileReport als HTML speichern\n",
    "webbrowser.open(f\"file://{path_pr}\")  # ProfileReport im Browser öffnen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Datenaufbereitung**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus dem Abschnitt \"Daten verstehen\" geht hervor, dass alle Variablen numerisch sind und somit keine Transformation benötigen. \n",
    "Ferner wird der Datensatz auf Duplikate und NaN-Werte geprüft und bereinigt.\n",
    "Die Duplikate werden gelöscht, wie auch die NaN-Werte, da hierzu keine geeigneten Informationen zur Imputation vorhanden sind.\n",
    "Vor dem Hintergrund, dass die Modellergebnisse auf ihre Fairness geprüft wird, wird die Spalte Age in zwei Kategorien (jung/alt) geteilt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplikate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bestimmung der Anzahl der Duplikate\n",
    "df_duplicates = df[df.duplicated()]\n",
    "print(f'Dieser Datensatz besitz {len(df_duplicates)} Duplikate.')\n",
    "\n",
    "# Bestimmung der Anzahl der Duplikate pro Klasse\n",
    "duplicates_per_class = df_duplicates['SeriousDlqin2yrs'].value_counts()\n",
    "print(f'Von den Duplikaten liegen {duplicates_per_class.get(0, 0)} Instanzen in der Klasse \"kein Zahlungsausfall\" (0) und {duplicates_per_class.get(1, 0)} Instanzen in der Klasse \"Zahlungsausfall\" (1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplikate werden gelöscht\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bestimmung der Variablen mit Nan-Werte mit der Anzahl der NaN-Einträge\n",
    "df.isnull().sum()[df.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeilen mit NaN-Werten werden gelöscht, da keine Informationen darüber vorliegen, wie die fehlenden Werte sinnvoll rekonstruiert werden könnten.\n",
    "df = df.dropna(subset=['MonthlyIncome'])\n",
    "df = df.dropna(subset=['NumberOfDependents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kategorie Alter erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spalte Age in zwei Kategorien teilen jung/alt\n",
    "df['age_categories'] = pd.cut(df['age'], bins=[0, 50, float('inf')], labels=[0, 1], right=False) # 0 = young, 1 = old\n",
    "df['age_categories'] = df['age_categories'].cat.codes\n",
    "print(df['age_categories'].value_counts())\n",
    "print('')\n",
    "print(pd.crosstab(df['age_categories'], df['SeriousDlqin2yrs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Machine Learning Modellierung** \n",
    "\n",
    "Für das Training von Klassifikationsmodelle werden die supervised ML Modelle RF, LR und XGBoost verwendet. Diese drei Modelle repräsentieren unterschiedliche Modelltypen, zeichnen sich durch ihre bewährte Leistungsfähigkeit aus und ermöglichen eine gezielte Anpassung der Hyperparameter (HP) auf Modellebene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funktionen für das Training und der Evaluierung der ML-Modelle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ergebnistabelle initialisieren (für die Speicherung der Evaluationskennzahlen)\n",
    "df_result = pd.DataFrame(columns=['model','method', 'balancedAccuracy', 'f1', 'rocAuc', 'dir', 'eo'])\n",
    "\n",
    "'''\n",
    "Funktion:       Ermittlung des Disperate Impact Ratio Wertes.\n",
    "Input:          y_pred (vom Modell vorhergesagte Zielvariable)\n",
    "                age_test (Werte des zu prüfenden Age Attributs)\n",
    "Output:         dri (ermittelter Disperate Impact Ratio Wert)\n",
    "Funktionsweise: Gemäß der Definition (DIR = P(Ŷ = 1 | A = 1) / P(Ŷ = 1 | A = 0) mit A = 1 geschütze Gruppe und A = 0 Referenzgruppe) wird der Disperate Impact Ratio Wert ermittelt. \n",
    "'''\n",
    "def getDisparateImpact(y_pred, age_test):\n",
    "    prop_young = y_pred[age_test == 0].mean() # P(Ŷ=1|A=young)\n",
    "    prop_old = y_pred[age_test == 1].mean() # P(Ŷ=1|A=old)\n",
    "\n",
    "    if prop_old == 0: # Divison durch 0 verhindern\n",
    "        return np.nan \n",
    "    \n",
    "    dir = prop_old / prop_young\n",
    "    return dir\n",
    "\n",
    "\n",
    "'''\n",
    "Funktion:       Training auf den Trainingsdaten und Vorhersage der Zielvariable auf den Testdaten für das übergebene Modell.\n",
    "Input:          ml_model (ausgewähltes zu trainierenden Modell), \n",
    "                X_train (Label der Trainingsdaten), \n",
    "                y_train (Feature der Trainingsdaten), \n",
    "                X_test (Label der Testdaten), \n",
    "                name (Name des zu trainierenden Modells), \n",
    "                algoAdaption (Variable, welche angibt, ob eine Klassen-Gewichtung bestimmt werden soll)\n",
    "                threshold (Schwellenwert für die Zuordnung einer Beobachtung zu einer bestimmeten Klasse)\n",
    "Output:         y_pred_model (vom Modell vorhergesagte Zielvariable)\n",
    "Funktionsweise: Das übergebende Modell wird auf den Trainingsdaten trainiert und eine Vorhersage für die Testdaten getroffen. '\n",
    "'''\n",
    "def runModel(ml_model, X_train, y_train, X_test, name, algoAdaption = False, threshold = 0.5):\n",
    "    name_print_out = name\n",
    "    print('[INFO] Model ' + name_print_out + ' started.') # Info-Meldung: Modelltraining Start\n",
    "\n",
    "    # Modell-Name\n",
    "    name = name.split()[0]\n",
    "    name = name.replace(\" \", \"\")\n",
    "\n",
    "    sampleWeights = compute_sample_weight(class_weight='balanced', y=y_train) if algoAdaption else None # Gewichtigung für das Training\n",
    "    ml_model.fit(X_train, y_train, sample_weight = sampleWeights) # Modell Training mit Trainings-daten \n",
    "    \n",
    "    # Für die Testdaten wird eine Vorhersage basierend auf dem trainierten Modell getroffen:\n",
    "    y_proba = ml_model.predict_proba(X_test)[:, 1] \n",
    "    y_pred_model = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    print('[INFO] Model ' + name_print_out + ' finished.') # Info-Meldung: Modelltraining Ende\n",
    "\n",
    "    return(y_pred_model)\n",
    "\n",
    "'''           \n",
    "Funktion:       Bestimmung der Evaluationskenntzahlen für das übergebende Modell \n",
    "Input:          y_pred_model (vorhergesagte Zielvariable), \n",
    "                y_test (tatsächlicher Zielvariable), \n",
    "                age_test (Test-Daten der kategorischen Age-Spalte),\n",
    "                name (Name des trainierte Modell), \n",
    "                df_result (Ergebnistabelle), \n",
    "                method (Methode zur Behebung unausgeglichener Daten)\n",
    "Output:         df_result (angepasste Ergebnistabelle), \n",
    "                (fpr, tpr, rocAuc) (ROC-Daten)\n",
    "Funktionsweise: Mithilfe der vorhergesagten und der tatsächlichen Zielvariablen wird die Balanced Accuracy, Precision, Recall, F1, ROC-AUC, FPR und TPR ermittelt. \n",
    "                Die ermittelten Kennzahlen und die Fairness-Kennzhalen werden in der Ergebistabelle mit dem Modellname und der Methodenname gespeichert.\n",
    "'''\n",
    "\n",
    "def getResults(y_pred_model, y_test, age_test, name, df_result, method):\n",
    "    # Bestimmung der Leistungskennzahlen\n",
    "    balancedAccuracy = balanced_accuracy_score(y_test, y_pred_model)\n",
    "    f1 = f1_score(y_test, y_pred_model)\n",
    "    rocAuc = roc_auc_score(y_test, y_pred_model)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_model)\n",
    "    rocAuc = auc(fpr, tpr)\n",
    "\n",
    "    # Bestimmung der Fairnessmetriken\n",
    "    disparate_impact_ratio = getDisparateImpact(y_pred_model, age_test) # Bestimmung der Kennzahl Disperate Impact Ratio\n",
    "    equal_opportunity = equalized_odds_difference(y_test, y_pred_model, sensitive_features=age_test)\n",
    "\n",
    "    # Speicherung der Kennzahlen \n",
    "    temp = pd.DataFrame([[name.split()[0], method, balancedAccuracy, f1,rocAuc, disparate_impact_ratio, equal_opportunity ]], columns=['model','method','balancedAccuracy', 'f1', 'rocAuc','dir', 'eo'])\n",
    "    df_result = pd.concat([df_result, temp], ignore_index=True)\n",
    "\n",
    "    return df_result, (fpr, tpr, rocAuc)\n",
    "\n",
    "'''\n",
    "Funktion:       Definierung der ML-Modelle inkl. Methode-Besonderheiten sowie Training und Evaluierung der Modelle\n",
    "Input:          X_train (Label der Trainingsdaten), \n",
    "                y_train (Feature der Trainingsdaten), \n",
    "                X_test (Label der Testdaten), \n",
    "                y_test (tatsächlicher Zielvariable), \n",
    "                age_test (Test-Daten der kategorischen Age-Spalte),\n",
    "                df_result (Ergebnistabelle), \n",
    "                method (Methode zur Behebung unausgeglichener Daten), \n",
    "                balanced (Gewicht-Parameter-Wert), \n",
    "                algo (Boolean-Wert der angibt, ob es sich um die Anpassung der Parameter Methode handelt)\n",
    "                threshold (Schwellenwert für die Zuordnung einer Beobachtung zu einer bestimmeten Klasse)\n",
    "Output:         df_result (angepasste Ergebnistabelle), \n",
    "                roc_data_dict (ROC-Daten)\n",
    "Funktionsweise: Abhängig von der Anpassung der Parameter Methode wird das Klassenverhätlnis für das XGBoost-Modell bestimmt. \n",
    "                Anschließend werden die Modelle mit ihren Methode-Besonderheiten definiert. Jedes Modell wird trainiert, getestet und evaluiert aauf die Modellleistung und Fairness.\n",
    "'''\n",
    "def runAndPredict(X_train, y_train, X_test, y_test, age_test,  df_result, method, balanced = None, algo = False, threshold = 0.5):\n",
    "    # Bei der Methode der Anpassung der Parameter wird das Verhältnis der beiden Zielvariablenklassen (0,1) bestimmt. \n",
    "    # Bei allen anderen Methoden wird keine Verhältnis bestimmt und auf 1 gesetzt.\n",
    "    ratio = 1 if algo == False else (sum(y_train == 0) / sum(y_train == 1))\n",
    "    if(ratio != 1):\n",
    "        print(f'Das Klassenverhältnis beträgt: {ratio}')\n",
    "\n",
    "    # Definierung der drei ML-Grundmodelle\n",
    "    rf_model = RandomForestClassifier(random_state=123, class_weight = balanced)\n",
    "    xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", eval_metric = 'auc', random_state=123, n_estimators=500, learning_rate=0.2, scale_pos_weight=ratio )\n",
    "    logReg_model = LogisticRegression(class_weight=balanced)\n",
    "\n",
    "    # Zuordnung zwischen Modell-Name (mit Methoden-Besonderheit) und Modell\n",
    "    ml_model = {\n",
    "        f'RF {method}': rf_model,\n",
    "        f'XGBoost {method}': xgb_model,\n",
    "        f'LR {method}': logReg_model\n",
    "    }\n",
    "    \n",
    "    roc_data_dict = {}\n",
    "\n",
    "    # Jedes Model wird trainiert und evaluiert\n",
    "    for modelName, model in ml_model.items():\n",
    "        y_pred = runModel(model, X_train, y_train, X_test, modelName, threshold = threshold) # Training und Vorhersage der Zievariable auf Testdaten\n",
    "\n",
    "        df_result, roc_data = getResults(y_pred, y_test, age_test,  modelName, df_result, method) # Evaluierung \n",
    "        roc_data_dict[modelName] = roc_data # Speicherung der ROC-Daten\n",
    "\n",
    "    return df_result, roc_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten in Test- und Trainingsdaten teilen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der Verteilung der Zielvariable SeriousDlqin2yrs\n",
    "count_label = df['SeriousDlqin2yrs'].value_counts()\n",
    "count_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafik: Verteilung der Zielvariable SeriousDlqin2yrs\n",
    "plt.bar(count_label.index, count_label.values, color=['blue', 'red'])\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Anzahl Vorkommen')\n",
    "plt.title('Verteilung der Zielvariable SeriousDlqin2yrs')\n",
    "plt.xticks(ticks=[0, 1], labels=[\"kein Zahlungsausfall\", \"Zahlungsausfall\"])\n",
    "y_text_position = min(count_label.values) * 0.1\n",
    "for i, v in enumerate(count_label.values):\n",
    "    plt.text(i, y_text_position, str(v), ha='center', va='bottom', color='white', fontsize=10)\n",
    "plt.savefig(\"output/distribution_targetVariable.png\", dpi=300, bbox_inches=\"tight\") # Grafik speichern\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten im Verhätlnis 80%-20% (Training-Test) aufteilen\n",
    "X = df.drop(columns=['SeriousDlqin2yrs', 'age_categories'])\n",
    "y = df['SeriousDlqin2yrs']\n",
    "age = df['age_categories']\n",
    "\n",
    "X_train, X_test, y_train, y_test, age_train, age_test = train_test_split(X, y, age, test_size=0.2, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skalierung \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Basismodell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwendung der Funktion runAndPredict ohne Anpassungenm \n",
    "df_result, roc_data = runAndPredict(X_train_scaled, y_train, X_test_scaled, y_test, age_test, df_result, 'Baseline' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Datenebene**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling\n",
    "\n",
    "#### Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling durchführen\n",
    "print('Ursprüngliche Klassenvertilung %s' % Counter(y))\n",
    "\n",
    "rus = RandomUnderSampler(random_state=123)\n",
    "X_rus, y_rus = rus.fit_resample(X, y)\n",
    "\n",
    "selected_indices = rus.sample_indices_\n",
    "age_rus = age.reset_index(drop=True).iloc[selected_indices].reset_index(drop=True)\n",
    "\n",
    "print('Neue Klassenverteilung mit Undersampling:', Counter(y_rus))\n",
    "X_train_rus, X_test_rus, y_train_rus, y_test_rus, age_rus_train, age_rus_test = train_test_split(X_rus, y_rus, age_rus, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skalierung \n",
    "scaler = StandardScaler()\n",
    "X_train_rus_scaled = scaler.fit_transform(X_train_rus)\n",
    "X_test_rus_scaled = scaler.transform(X_test_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwendung der Funktion runAndPredict mit Undersampling\n",
    "df_result, roc_data_rus = runAndPredict(X_train_rus_scaled, y_train_rus, X_test_rus_scaled, y_test_rus, age_rus_test,  df_result, 'RUS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tomek Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ursprüngliche Klassenvertilung %s' % Counter(y))\n",
    "\n",
    "tl = TomekLinks(sampling_strategy='majority')  # Nur Mehrheitsklasse wird reduziert\n",
    "X_train_tl, y_train_tl = tl.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Neue Klassenverteilung mit Tomek Links:', Counter(y_train_tl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skalierung \n",
    "scaler = StandardScaler()\n",
    "X_train_tl_scaled = scaler.fit_transform(X_train_tl)\n",
    "X_test_tl_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwendung der Funktion runAndPredict mit Tomek Links\n",
    "df_result, roc_data_tl = runAndPredict(X_train_tl_scaled, y_train_tl, X_test_tl_scaled, y_test, age_test, df_result, 'TL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling\n",
    "\n",
    "#### Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling durchführen \n",
    "print('Ursprüngliche Klassenvertilung %s' % Counter(y))\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy='minority')\n",
    "X_ros, y_ros = ros.fit_resample(X, y)\n",
    "\n",
    "selected_indices = ros.sample_indices_\n",
    "age_ros = age.reset_index(drop=True).iloc[selected_indices].reset_index(drop=True)\n",
    "\n",
    "print('Neue Klassenverteilung mit Undersampling:', Counter(y_ros))\n",
    "X_train_ros, X_test_ros, y_train_ros, y_test_ros, age_ros_train, age_ros_test = train_test_split(X_ros, y_ros, age_ros, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skalierung \n",
    "scaler = StandardScaler()\n",
    "X_train_ros_scaled = scaler.fit_transform(X_train_ros)\n",
    "X_test_ros_scaled = scaler.transform(X_test_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwendung der Funktion runAndPredict mit Oversampling\n",
    "df_result, roc_data_ros = runAndPredict(X_train_ros_scaled, y_train_ros, X_test_ros_scaled, y_test_ros,age_ros_test, df_result, 'ROS' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE durchführen\n",
    "print('Ursprüngliche Klassenvertilung %s' % Counter(y))\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Neue Klassenverteilung mit SMOTE:', Counter(y_train_smote))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skalierung \n",
    "scaler = StandardScaler()\n",
    "X_train_smote_scaled = scaler.fit_transform(X_train_smote)\n",
    "X_test_smote_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwendung der Funktion runAndPredict mit SMOTE\n",
    "df_result, roc_data_smote = runAndPredict(X_train_smote_scaled, y_train_smote, X_test_smote_scaled, y_test, age_test, df_result, 'SMOTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Modellebene** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anpassung der Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwendung der Funktion runAndPredict mit angepassten Hyperparameter \n",
    "df_result, roc_data_hp = runAndPredict(X_train_scaled, y_train, X_test_scaled, y_test, age_test, df_result, 'HP', balanced = \"balanced\",algo = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threshold Moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwendung der Funktion runAndPredict mit angepassten Treshold\n",
    "df_result, roc_data_tm = runAndPredict(X_train_scaled, y_train, X_test_scaled, y_test, age_test, df_result, 'TM', threshold = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vergleich der Evaluationskennzahlen (Tabelle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_result.sort_values(by=['method', 'model'])\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pro Kennzahl wird die beste Methoden-Modell Kombination bestimmt\n",
    "\n",
    "df_result['ModelKind'] = df_result['model'] + '-' + df_result['method']\n",
    "\n",
    "# Ausgabe der besten Methode pro Kennzahl\n",
    "for i in ['balancedAccuracy',  'f1', 'rocAuc', 'dir', 'eo']:\n",
    "    if i == 'eo':\n",
    "       min_value_row = df_result.loc[df_result[i].idxmin()]  # Bestimme Zeile mit Minimalen-Wert\n",
    "       min_value_kind = min_value_row['ModelKind'] \n",
    "       print(f\"Minimaler Wert {i} = {min_value_row[i]} beim Modell {min_value_kind}.\")\n",
    "    else:\n",
    "        max_value_row = df_result.loc[df_result[i].idxmax()]  # Bestimme Zeile mit Maximalen-Wert\n",
    "        max_value_kind = max_value_row['ModelKind']\n",
    "        print(f\"Maximale Wert {i} = {max_value_row[i]} beim Modell {max_value_kind}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vergleich der Evaluationskennzahlen (Grafiken)\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methoden-Liste\n",
    "resampling_methods = [\"Baseline\", \"RUS\", \"TL\",  \"ROS\", \"SMOTE\", \"HP\", \"TM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metriken-Liste \n",
    "metrics = [\"balancedAccuracy\", \"f1\"]\n",
    "\n",
    "# Grafiken pro Metrik\n",
    "fig, axes = plt.subplots(nrows=len(metrics), ncols=1, figsize=(8, 6 * len(metrics)))\n",
    "for ax, i in zip(axes, metrics):\n",
    "    sns.barplot(data=df_result, x=\"method\", y=i, hue=\"model\", order=resampling_methods, ax=ax)\n",
    "    ax.set_title(i)\n",
    "    ax.set_xlabel(\"Methode\")\n",
    "    ax.set_ylabel('')\n",
    "    ax.legend(title=\"Modell\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "# Gesamt-Grafik speichern\n",
    "plt.savefig(\"output/evaluation_metrics.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metrik Disparate Impact Grafik \n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.barplot(data=df_result, x=\"method\", y='dir', hue=\"model\", order=resampling_methods, ax=ax)\n",
    "ax.set_title('Disparate Impact')\n",
    "ax.set_xlabel(\"Methode\")\n",
    "ax.set_ylabel('')\n",
    "ax.axhline(y=0.8, color='red', linestyle='--', linewidth=1.5)\n",
    "ax.legend(title=\"Modell\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/evaluation_metrics_disparate_impact.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metrik Equal Opportunity\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.barplot(data=df_result, x=\"method\", y='eo', hue=\"model\", order=resampling_methods, ax=ax)\n",
    "ax.set_title('Equal Opportunity')\n",
    "ax.set_xlabel(\"Methode\")\n",
    "ax.set_ylabel('')\n",
    "ax.axhline(y=0.1, color='red', linestyle='--', linewidth=1.5)\n",
    "ax.legend(title=\"Modell\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/evaluation_metrics_equal_opportunity.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Funktion:       Erstellung ROC-AUC-Kurve für die verschiedenen Methoden zur Behebung unausgeglichener Daten\n",
    "Input:          roc_data_list (roc_data)\n",
    "                methodTitles (Methode zur Behebung unausgeglichener Daten für die Anzeige im Titel)\n",
    "Funktionsweise: Basierend auf den gespeicherten ROC-Daten wird die ROC-AUC-Kurve für die drei ML-Modell pro Methode dargestellt.\n",
    "'''\n",
    "def plot_roc_curves(roc_data_list, methodTitles):\n",
    "    num_plots = len(roc_data_list)\n",
    "    num_cols = 2  \n",
    "    num_rows = (num_plots + 1) // num_cols  \n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 6 * num_rows))\n",
    "    axes = axes.flatten()  \n",
    "    \n",
    "    # Farben der einzelnen ML-Modelle festlegen\n",
    "    colors = {\n",
    "        'RF': 'blue',\n",
    "        'XGBoost': 'red',\n",
    "        'LR': 'orange'\n",
    "    }\n",
    "    \n",
    "    # Pro Methode werden pro Modell die dazugehörige ROC-AUC-Kurve in die Grafik eingezeichnet\n",
    "    for idx, (roc_data, methodTitles) in enumerate(zip(roc_data_list, methodTitles)):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        for model_name, (fpr, tpr, auc) in roc_data.items():\n",
    "            ax.plot(fpr, tpr, color=colors.get(model_name.split()[0], 'black'), lw=1,\n",
    "                    label=f'{model_name} (AUC = {auc:.2f})')\n",
    "        \n",
    "        ax.plot([0, 1], [0, 1], color='gray', lw=0.5, linestyle='--')\n",
    "        ax.set_xlim([0.0, 1.0])\n",
    "        ax.set_ylim([0.0, 1.05])\n",
    "        ax.set_xlabel('FPR')\n",
    "        ax.set_ylabel('TPR')\n",
    "        ax.set_title(f'ROC-AUC: {methodTitles}')\n",
    "        ax.legend(loc=\"lower right\")\n",
    "    \n",
    "    if num_plots % 2 != 0:\n",
    "        fig.delaxes(axes[-1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # Gesamt-Grafik speichern\n",
    "    plt.savefig('output/evaluation_roc_auc.png', dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "roc_data_list = [roc_data,  roc_data_rus, roc_data_tl, roc_data_ros, roc_data_smote, roc_data_hp, roc_data_tm] # ROC-Daten-Liste\n",
    "titles = ['Baseline', 'Random Undersampling', \"Tomek Links\", 'Random Oversampling', 'SMOTE', 'Anpassung Hyperparameter', \"Threshold Moving\"] # Methodennamen-Liste\n",
    "plot_roc_curves(roc_data_list, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
